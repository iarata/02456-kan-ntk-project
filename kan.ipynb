{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional_KANs  __pycache__  efficientKAN.py  kan_convolutional\n",
      "Few-KAN\t\t    data\t env\t\t  wandb\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/AntonioTepsich/Convolutional-KANs\n",
    "# !pip install tqdm pyprof\n",
    "# !mv 'Convolutional-KANs' Convolutional_KANs\n",
    "# !cd Convolutional_KANs && mv kan_convolutional .. \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# export CUDA_VISIBLE_DEVICES=0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import torchvision as tv\n",
    "import torch.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "from efficientKAN import KAN as EfficientKAN\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer as KANConv\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "seed_val = 42\n",
    "L.seed_everything(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KANDataModule(L.LightningDataModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning DataModule for handling CIFAR10 and MNIST datasets.\n",
    "    Provides unified interface and preprocessing for both datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"data\",\n",
    "        dataset_name: str = \"cifar10\",  # \"cifar10\" or \"mnist\"\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "        val_split: float = 0.2,\n",
    "        random_seed: int = 42,\n",
    "        img_size: int = 32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.dataset_name = dataset_name.lower()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split = val_split\n",
    "        self.random_seed = random_seed\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        if self.dataset_name not in [\"cifar10\", \"mnist\"]:\n",
    "            raise ValueError(\"dataset_name must be either 'cifar10' or 'mnist'\")\n",
    "        \n",
    "        self.num_classes = 10\n",
    "        self.channels = 3 if self.dataset_name == \"cifar10\" else 1\n",
    "        \n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def _get_transforms(self) -> Tuple[transforms.Compose, transforms.Compose]:\n",
    "        \"\"\"\n",
    "        Returns train and test transforms for the selected dataset.\n",
    "        Train transforms include augmentations, test transforms only include normalization.\n",
    "        \"\"\"\n",
    "        if self.dataset_name == \"cifar10\":\n",
    "            # CIFAR10 normalization values\n",
    "            mean = [0.4914, 0.4822, 0.4465]\n",
    "            std = [0.2470, 0.2435, 0.2616]\n",
    "            \n",
    "            train_transforms = transforms.Compose([\n",
    "                transforms.Resize(self.img_size, interpolation=InterpolationMode.BILINEAR),\n",
    "                transforms.RandomCrop(self.img_size, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ])\n",
    "            \n",
    "            test_transforms = transforms.Compose([\n",
    "                transforms.Resize(self.img_size, interpolation=InterpolationMode.BILINEAR),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ])\n",
    "        \n",
    "        else:\n",
    "            # MNIST normalization values\n",
    "            mean = [0.1307]\n",
    "            std = [0.3081]\n",
    "            \n",
    "            train_transforms = transforms.Compose([\n",
    "                transforms.Resize(self.img_size, interpolation=InterpolationMode.BILINEAR),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ])\n",
    "            \n",
    "            test_transforms = transforms.Compose([\n",
    "                transforms.Resize(self.img_size, interpolation=InterpolationMode.BILINEAR),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ])\n",
    "        \n",
    "        return train_transforms, test_transforms\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Downloads the dataset if not already present.\n",
    "        \"\"\"\n",
    "        if self.dataset_name == \"cifar10\":\n",
    "            datasets.CIFAR10(self.data_dir, train=True, download=True)\n",
    "            datasets.CIFAR10(self.data_dir, train=False, download=True)\n",
    "        else:\n",
    "            datasets.MNIST(self.data_dir, train=True, download=True)\n",
    "            datasets.MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Sets up train, validation, and test datasets.\n",
    "        \"\"\"\n",
    "        train_transforms, test_transforms = self._get_transforms()\n",
    "        \n",
    "        if stage == \"fit\" or stage is None:\n",
    "            if self.dataset_name == \"cifar10\":\n",
    "                full_dataset = datasets.CIFAR10(\n",
    "                    self.data_dir, train=True, transform=train_transforms\n",
    "                )\n",
    "            else:\n",
    "                full_dataset = datasets.MNIST(\n",
    "                    self.data_dir, train=True, transform=train_transforms\n",
    "                )\n",
    "            \n",
    "            val_length = int(len(full_dataset) * self.val_split)\n",
    "            train_length = len(full_dataset) - val_length\n",
    "            \n",
    "            self.train_dataset, self.val_dataset = random_split(\n",
    "                full_dataset,\n",
    "                [train_length, val_length],\n",
    "                generator=torch.Generator().manual_seed(self.random_seed)\n",
    "            )\n",
    "            \n",
    "            self.val_dataset.dataset.transform = test_transforms\n",
    "        \n",
    "        if stage == \"test\" or stage is None:\n",
    "            if self.dataset_name == \"cifar10\":\n",
    "                self.test_dataset = datasets.CIFAR10(\n",
    "                    self.data_dir, train=False, transform=test_transforms\n",
    "                )\n",
    "            else:\n",
    "                self.test_dataset = datasets.MNIST(\n",
    "                    self.data_dir, train=False, transform=test_transforms\n",
    "                )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamesePair(Dataset):\n",
    "    \"\"\"Dataset wrapper that creates Siamese pairs from a base dataset\"\"\"\n",
    "    def __init__(self, dataset, labels_to_indices: Dict[int, List[int]], same_pair_ratio: float = 0.5):\n",
    "        self.dataset = dataset\n",
    "        self.labels_to_indices = labels_to_indices\n",
    "        self.same_pair_ratio = same_pair_ratio\n",
    "        self.classes = list(labels_to_indices.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img1, label1 = self.dataset[idx]\n",
    "        \n",
    "        should_get_same_class = np.random.random() < self.same_pair_ratio\n",
    "        \n",
    "        if should_get_same_class:\n",
    "            label2 = label1\n",
    "            idx2 = np.random.choice(self.labels_to_indices[label1])\n",
    "            while idx2 == idx: \n",
    "                idx2 = np.random.choice(self.labels_to_indices[label1])\n",
    "        else:\n",
    "            label2 = np.random.choice([c for c in self.classes if c != label1])\n",
    "            idx2 = np.random.choice(self.labels_to_indices[label2])\n",
    "            \n",
    "        img2, _ = self.dataset[idx2]\n",
    "        target = torch.tensor(1.0 if label1 == label2 else 0.0, dtype=torch.float32)\n",
    "        \n",
    "        return (img1, img2), target\n",
    "\n",
    "\n",
    "class FewShotDataModule(L.LightningDataModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning DataModule for few-shot learning on CIFAR10 and MNIST datasets.\n",
    "    Provides support for N-shot K-way classification tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"data\",\n",
    "        dataset_name: str = \"cifar10\",  # \"cifar10\" or \"mnist\"\n",
    "        shots_per_class: int = 5,  # N-shot\n",
    "        ways: int = 5,  # K-way\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "        val_split: float = 0.2,\n",
    "        random_seed: int = 42,\n",
    "        img_size: int = 32,\n",
    "        test_split_ratio: float = 0.2,  # Ratio of classes to reserve for testing\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.dataset_name = dataset_name.lower()\n",
    "        self.shots_per_class = shots_per_class\n",
    "        self.ways = ways\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split = val_split\n",
    "        self.random_seed = random_seed\n",
    "        self.img_size = img_size\n",
    "        self.test_split_ratio = test_split_ratio\n",
    "        \n",
    "        if self.dataset_name not in [\"cifar10\", \"mnist\"]:\n",
    "            raise ValueError(\"dataset_name must be either 'cifar10' or 'mnist'\")\n",
    "        \n",
    "        self.num_classes = 10\n",
    "        self.channels = 3 if self.dataset_name == \"cifar10\" else 1\n",
    "        \n",
    "        self.num_test_classes = int(self.num_classes * self.test_split_ratio)\n",
    "        self.num_train_classes = self.num_classes - self.num_test_classes\n",
    "\n",
    "    def _get_transforms(self) -> Tuple[transforms.Compose, transforms.Compose]:\n",
    "        \"\"\"Returns train and test transforms for the selected dataset.\"\"\"\n",
    "        if self.dataset_name == \"cifar10\":\n",
    "            mean = [0.4914, 0.4822, 0.4465]\n",
    "            std = [0.2470, 0.2435, 0.2616]\n",
    "        else:\n",
    "            mean = [0.1307]\n",
    "            std = [0.3081]\n",
    "            \n",
    "        train_transforms = transforms.Compose([\n",
    "            transforms.Resize(self.img_size, interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ])\n",
    "        \n",
    "        test_transforms = transforms.Compose([\n",
    "            transforms.Resize(self.img_size, interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ])\n",
    "        \n",
    "        return train_transforms, test_transforms\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Downloads the dataset if not already present.\"\"\"\n",
    "        if self.dataset_name == \"cifar10\":\n",
    "            datasets.CIFAR10(self.data_dir, train=True, download=True)\n",
    "            datasets.CIFAR10(self.data_dir, train=False, download=True)\n",
    "        else:\n",
    "            datasets.MNIST(self.data_dir, train=True, download=True)\n",
    "            datasets.MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def _create_few_shot_dataset(self, dataset, classes: List[int]) -> Tuple[Dataset, Dict[int, List[int]]]:\n",
    "        \"\"\"Creates a few-shot dataset by selecting N examples per class.\"\"\"\n",
    "        labels_to_indices = {label: [] for label in classes}\n",
    "        selected_indices = []\n",
    "        \n",
    "        for idx, (_, label) in enumerate(dataset):\n",
    "            if label in classes:\n",
    "                labels_to_indices[label].append(idx)\n",
    "        \n",
    "        for label in classes:\n",
    "            indices = np.array(labels_to_indices[label])\n",
    "            selected = indices[np.random.choice(len(indices), \n",
    "                                             size=min(self.shots_per_class, len(indices)), \n",
    "                                             replace=False)]\n",
    "            selected_indices.extend(selected.tolist())\n",
    "            \n",
    "            labels_to_indices[label] = selected.tolist()\n",
    "        \n",
    "        few_shot_dataset = Subset(dataset, selected_indices)\n",
    "        return few_shot_dataset, labels_to_indices\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Sets up train, validation, and test datasets.\"\"\"\n",
    "        train_transforms, test_transforms = self._get_transforms()\n",
    "        \n",
    "        if self.dataset_name == \"cifar10\":\n",
    "            full_dataset = datasets.CIFAR10(self.data_dir, train=True, transform=train_transforms)\n",
    "            test_dataset = datasets.CIFAR10(self.data_dir, train=False, transform=test_transforms)\n",
    "        else:\n",
    "            full_dataset = datasets.MNIST(self.data_dir, train=True, transform=train_transforms)\n",
    "            test_dataset = datasets.MNIST(self.data_dir, train=False, transform=test_transforms)\n",
    "        \n",
    "        all_classes = np.arange(self.num_classes)\n",
    "        np.random.shuffle(all_classes)\n",
    "        self.train_classes = all_classes[:-self.num_test_classes].tolist()\n",
    "        self.test_classes = all_classes[-self.num_test_classes:].tolist()\n",
    "        \n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_dataset, train_labels_to_indices = self._create_few_shot_dataset(\n",
    "                full_dataset, self.train_classes\n",
    "            )\n",
    "            \n",
    "            train_size = int((1 - self.val_split) * len(train_dataset))\n",
    "            val_size = len(train_dataset) - train_size\n",
    "            \n",
    "            self.train_dataset, self.val_dataset = torch.utils.data.random_split(\n",
    "                train_dataset,\n",
    "                [train_size, val_size],\n",
    "                generator=torch.Generator().manual_seed(self.random_seed)\n",
    "            )\n",
    "            \n",
    "            self.train_dataset = SiamesePair(self.train_dataset, train_labels_to_indices)\n",
    "            self.val_dataset = SiamesePair(self.val_dataset, train_labels_to_indices)\n",
    "        \n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset, test_labels_to_indices = self._create_few_shot_dataset(\n",
    "                test_dataset, self.test_classes\n",
    "            )\n",
    "            self.test_dataset = SiamesePair(self.test_dataset, test_labels_to_indices)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KANModule(L.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning module for KAN Networks with integrated W&B logging\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"kan_basic\",  # kan_basic, kan_plus, kan_deep\n",
    "        num_classes: int = 10,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 1e-5,\n",
    "        channels: int = 3,  # 3 for CIFAR10, 1 for MNIST\n",
    "        img_size: int = 32,\n",
    "        hidden_dim: int = 128,\n",
    "        num_layers: int = 3,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = self._create_model()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "        self.val_predictions = []\n",
    "        self.val_targets = []\n",
    "\n",
    "    def _create_model(self) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Create the specified KAN architecture\n",
    "        \"\"\"\n",
    "        input_dim = self.hparams.channels * self.hparams.img_size * self.hparams.img_size\n",
    "        \n",
    "        if self.hparams.model_name == \"kan_basic\":\n",
    "            return KANBasic(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=self.hparams.hidden_dim,\n",
    "                num_classes=self.hparams.num_classes,\n",
    "                dropout=self.hparams.dropout\n",
    "            )\n",
    "        elif self.hparams.model_name == \"kan_with_CNN\":\n",
    "            return KANwithCNN(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=self.hparams.hidden_dim,\n",
    "                num_classes=self.hparams.num_classes,\n",
    "                num_layers=self.hparams.num_layers,\n",
    "                dropout=self.hparams.dropout\n",
    "            )\n",
    "        elif self.hparams.model_name == \"kkan\":\n",
    "            return KKan(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=self.hparams.hidden_dim,\n",
    "                num_classes=self.hparams.num_classes,\n",
    "                num_layers=self.hparams.num_layers,\n",
    "                dropout=self.hparams.dropout\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name: {self.hparams.model_name}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.1,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        self.train_acc(preds, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", self.train_acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        self.val_predictions.extend(preds.cpu().numpy())\n",
    "        self.val_targets.extend(y.cpu().numpy())\n",
    "        \n",
    "        self.val_acc(preds, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Create and log visualizations to W&B at the end of validation\n",
    "        \"\"\"\n",
    "        y_pred = np.array(self.val_predictions)\n",
    "        y_true = np.array(self.val_targets)\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - Epoch {self.current_epoch}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        \n",
    "        wandb.log({\n",
    "            \"confusion_matrix\": wandb.Image(plt),\n",
    "            \"epoch\": self.current_epoch\n",
    "        })\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(y_pred, bins=self.hparams.num_classes, alpha=0.5, label='Predictions')\n",
    "        plt.hist(y_true, bins=self.hparams.num_classes, alpha=0.5, label='Ground Truth')\n",
    "        plt.title(f'Prediction Distribution - Epoch {self.current_epoch}')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "        \n",
    "        wandb.log({\n",
    "            \"prediction_distribution\": wandb.Image(plt),\n",
    "            \"epoch\": self.current_epoch\n",
    "        })\n",
    "        \n",
    "        self.val_predictions = []\n",
    "        self.val_targets = []\n",
    "        \n",
    "        plt.close('all')\n",
    "\n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        self.test_acc(preds, y)\n",
    "        \n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", self.test_acc)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# KAN Model Architectures\n",
    "class KANBasic(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, num_classes: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            EfficientKAN([input_dim, input_dim//2, input_dim//4, 64, num_classes]),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "class KANwithCNN(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, num_classes: int, num_layers: int = 3, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.img_size = int(np.sqrt(input_dim))\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.conv_output_dim = 64 * (self.img_size // 4) * (self.img_size // 4)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Linear(self.conv_output_dim, hidden_dim),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(hidden_dim, num_classes)\n",
    "            nn.Dropout(dropout),\n",
    "            EfficientKAN([self.conv_output_dim, self.conv_output_dim//2, self.conv_output_dim//4, 64, num_classes]),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.view(-1, 1, self.img_size, self.img_size)\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class KKan(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, num_classes: int, num_layers: int = 3, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.img_size = int(np.sqrt(input_dim)) \n",
    "        \n",
    "        self.conv1 = KANConv(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=(3,3),\n",
    "        )\n",
    "\n",
    "        self.conv2 = KANConv(\n",
    "            in_channels=6,\n",
    "            out_channels=12,\n",
    "            kernel_size=(3,3),\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        conv_output_size = ((self.img_size - 2) // 2 - 2) // 2\n",
    "        self.linear1 = nn.Linear(12 * conv_output_size * conv_output_size, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 1, self.img_size, self.img_size)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "    #     self.img_size = int(np.sqrt(input_dim // 3))\n",
    "        \n",
    "    #     self.conv1 = KANConv(\n",
    "    #         in_channels=3,  # Changed from 1 to 3 for RGB\n",
    "    #         out_channels=5,\n",
    "    #         kernel_size=(3,3),\n",
    "    #     )\n",
    "\n",
    "    #     self.conv2 = KANConv(\n",
    "    #         in_channels=5,\n",
    "    #         out_channels=5,\n",
    "    #         kernel_size=(3,3),\n",
    "    #     )\n",
    "\n",
    "    #     self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "    #     self.flat = nn.Flatten()\n",
    "        \n",
    "    #     # Calculate the size after convolutions and pooling\n",
    "    #     conv_output_size = ((self.img_size // 2) // 2)  # After two pooling layers\n",
    "    #     self.linear1 = nn.Linear(180, num_classes)\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     # Reshape the flattened input back to image format\n",
    "    #     x = x.view(x.size(0), 3, self.img_size, self.img_size)\n",
    "        \n",
    "    #     x = self.conv1(x)\n",
    "    #     x = self.pool1(x)\n",
    "        \n",
    "    #     x = self.conv2(x)\n",
    "    #     x = self.pool1(x)\n",
    "        \n",
    "    #     x = self.flat(x)\n",
    "    #     x = self.linear1(x)\n",
    "    #     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseKANModule(L.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning module for Siamese Networks with KAN architectures\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"kan_basic\",  # kan_basic, kan_with_cnn, kkan\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 1e-5,\n",
    "        channels: int = 3,  # 3 for CIFAR10, 1 for MNIST\n",
    "        img_size: int = 32,\n",
    "        hidden_dim: int = 128,\n",
    "        embedding_dim: int = 64,\n",
    "        num_layers: int = 3,\n",
    "        dropout: float = 0.5,\n",
    "        margin: float = 1.0,  # Margin for contrastive loss\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Initialize Siamese network with specified backbone\n",
    "        self.backbone = self._create_backbone()\n",
    "        \n",
    "        input_dim = self._get_backbone_output_dim()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        \n",
    "        self.val_predictions = []\n",
    "        self.val_targets = []\n",
    "        \n",
    "        self.margin = margin\n",
    "\n",
    "    def _get_backbone_output_dim(self) -> int:\n",
    "        \"\"\"Calculate the output dimension of the backbone network\"\"\"\n",
    "        x = torch.randn(1, self.hparams.channels, self.hparams.img_size, self.hparams.img_size)\n",
    "        with torch.no_grad():\n",
    "            out = self.backbone(x)\n",
    "        return out.numel()\n",
    "\n",
    "    def _create_backbone(self) -> nn.Module:\n",
    "        \"\"\"Create the specified KAN architecture as backbone\"\"\"\n",
    "        input_dim = self.hparams.channels * self.hparams.img_size * self.hparams.img_size\n",
    "        \n",
    "        if self.hparams.model_name == \"kan_basic\":\n",
    "            return KANBasic(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=self.hparams.hidden_dim,\n",
    "                num_classes=self.hparams.embedding_dim,\n",
    "                dropout=self.hparams.dropout\n",
    "            )\n",
    "        elif self.hparams.model_name == \"kan_with_cnn\":\n",
    "            return KANwithCNN(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=self.hparams.hidden_dim,\n",
    "                num_classes=self.hparams.embedding_dim,\n",
    "                num_layers=self.hparams.num_layers,\n",
    "                dropout=self.hparams.dropout\n",
    "            )\n",
    "        elif self.hparams.model_name == \"kkan\":\n",
    "            return KKan(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=self.hparams.hidden_dim,\n",
    "                num_classes=self.hparams.embedding_dim,\n",
    "                num_layers=self.hparams.num_layers,\n",
    "                dropout=self.hparams.dropout\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name: {self.hparams.model_name}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass for a single image\"\"\"\n",
    "        features = self.backbone(x)\n",
    "        embeddings = self.projection(features.view(features.size(0), -1))\n",
    "        return embeddings\n",
    "\n",
    "    def _shared_step(self, batch: Tuple[Tuple[torch.Tensor, torch.Tensor], torch.Tensor]) -> Dict:\n",
    "        \"\"\"Shared step for training, validation and testing\"\"\"\n",
    "        (img1, img2), target = batch\n",
    "        \n",
    "        embed1 = self(img1)\n",
    "        embed2 = self(img2)\n",
    "        \n",
    "        distance = F.pairwise_distance(embed1, embed2)\n",
    "        \n",
    "        loss = F.margin_ranking_loss(\n",
    "            distance,\n",
    "            target.float(),\n",
    "            torch.ones_like(target.float()) * self.margin,\n",
    "            margin=self.margin\n",
    "        )\n",
    "        \n",
    "        pred = (distance < self.margin/2).float()\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'distance': distance,\n",
    "            'preds': pred,\n",
    "            'targets': target.float()\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch: Tuple[Tuple[torch.Tensor, torch.Tensor], torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        outputs = self._shared_step(batch)\n",
    "        \n",
    "        self.train_acc(outputs['preds'], outputs['targets'])\n",
    "        \n",
    "        self.log('train_loss', outputs['loss'], prog_bar=True)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True)\n",
    "        \n",
    "        return outputs['loss']\n",
    "\n",
    "    def validation_step(self, batch: Tuple[Tuple[torch.Tensor, torch.Tensor], torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        outputs = self._shared_step(batch)\n",
    "        \n",
    "        self.val_predictions.extend(outputs['preds'].cpu().numpy())\n",
    "        self.val_targets.extend(outputs['targets'].cpu().numpy())\n",
    "        \n",
    "        self.val_acc(outputs['preds'], outputs['targets'])\n",
    "        \n",
    "        self.log('val_loss', outputs['loss'], prog_bar=True)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "        \n",
    "        return outputs['loss']\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Create and log visualizations to W&B\"\"\"\n",
    "        if len(self.val_predictions) == 0:\n",
    "            return\n",
    "            \n",
    "        y_pred = np.array(self.val_predictions)\n",
    "        y_true = np.array(self.val_targets)\n",
    "        \n",
    "        cm = np.zeros((2, 2))\n",
    "        for i in range(len(y_pred)):\n",
    "            cm[int(y_true[i]), int(y_pred[i])] += 1\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - Epoch {self.current_epoch}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        \n",
    "        wandb.log({\n",
    "            \"confusion_matrix\": wandb.Image(plt),\n",
    "            \"epoch\": self.current_epoch\n",
    "        })\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(y_pred, bins=2, alpha=0.5, label='Predictions')\n",
    "        plt.hist(y_true, bins=2, alpha=0.5, label='Ground Truth')\n",
    "        plt.title(f'Prediction Distribution - Epoch {self.current_epoch}')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "        \n",
    "        wandb.log({\n",
    "            \"prediction_distribution\": wandb.Image(plt),\n",
    "            \"epoch\": self.current_epoch\n",
    "        })\n",
    "        \n",
    "        self.val_predictions = []\n",
    "        self.val_targets = []\n",
    "        \n",
    "        plt.close('all')\n",
    "\n",
    "    def test_step(self, batch: Tuple[Tuple[torch.Tensor, torch.Tensor], torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        outputs = self._shared_step(batch)\n",
    "        \n",
    "        self.test_acc(outputs['preds'], outputs['targets'])\n",
    "        \n",
    "        self.log('test_loss', outputs['loss'])\n",
    "        self.log('test_acc', self.test_acc)\n",
    "        \n",
    "        return outputs['loss']\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.1,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"mnist\", \"kkan\", \"kkan_mlp_linear\", \"v2\"]\n",
    "wandb_logger = WandbLogger(project=\"Few-KAN\", name=\".\".join(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KANModule(model_name=names[1], num_classes=10, channels=1, img_size=32, hidden_dim=128)\n",
    "data_module = KANDataModule(dataset_name=names[0])\n",
    "\n",
    "trainer = L.Trainer(max_epochs=100, logger=wandb_logger)\n",
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
