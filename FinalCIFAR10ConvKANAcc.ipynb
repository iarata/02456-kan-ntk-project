{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479bcedb-b14c-41f7-baca-bc5e77d9d2a9",
   "metadata": {},
   "source": [
    "# ConvKAN + CIFAR10\n",
    "Purpose: Fit a ConvKAN to the CIFAR10 dataset.\n",
    "\n",
    "This is the Accuracy variant, which means it seeks to find the highest performance using as much of the dataset as possible, while balancing the parameter count.\n",
    "\n",
    "Furthermore, the PyTorch Lightning library is used for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5906942-d959-4742-a7f5-3f0d9d1eb9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1000000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured CUDA Precision\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('convkans/kan_convolutional')\n",
    "from KANLinear import *\n",
    "from KANConv import KAN_Convolutional_Layer\n",
    "\n",
    "# Setup Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Setup Randomness -- https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "L.seed_everything(1000000007, workers=True) # <--- Adjust the seed here for each trial run for the 5 seed values [42, 998244353, 10122024, 1000000007, 68812].\n",
    "\n",
    "# CUDA Efficiency\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    print(\"Configured CUDA Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298f7983-dee7-49b7-a4b8-87218d313bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataset Setup -- Inspired by Hugo's Dataset Reformatting\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = CIFAR10(\"./Experiments/temp/\", train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(\"./Experiments/temp/\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = int(len(train_dataset) * 0.90)\n",
    "val_size = int(len(train_dataset)) - train_size\n",
    "train_set, val_set = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Reformatted, due to odd issues when using NTK on it\n",
    "class LCDataset(Dataset): # Lightning Compatible Dataset\n",
    "    def __init__(self, dataset, num_classes, limit=-1):\n",
    "        self.limit = limit\n",
    "        self.num_classes = num_classes\n",
    "        if self.limit != -1:\n",
    "            sub = list(np.random.permutation(np.arange(len(dataset)))[0:self.limit]) # Take a random sample of the first some elements.\n",
    "            self.dataset = Subset(dataset, sub)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        y_one_hot = torch.zeros(self.num_classes)\n",
    "        y_one_hot[y] = 1\n",
    "        return x, y_one_hot\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(LCDataset(train_set, num_classes=10), batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "val_loader = DataLoader(LCDataset(val_set, num_classes=10), batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "test_loader = DataLoader(LCDataset(test_dataset, num_classes=10), batch_size=batch_size, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf44a29-2a95-4e65-9372-1550ca2c8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Declaration\n",
    "class NetConvKAN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            KAN_Convolutional_Layer(in_channels=3, out_channels=16, kernel_size=(2, 2), grid_size=2, spline_order=2, device=device),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.GELU(),\n",
    "            nn.Flatten(1),\n",
    "            nn.Dropout(p=0.50),\n",
    "            nn.Linear(3600, 64, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.50),\n",
    "            nn.Linear(64, 10, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        v1 = torch.argmax(y_pred, dim=1)\n",
    "        v2 = torch.argmax(y, dim=1)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        accuracy = torch.sum(torch.eq(v1, v2)) / len(y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", accuracy, prog_bar=True) # Observe model accuracy with time\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        v1 = torch.argmax(y_pred, dim=1)\n",
    "        v2 = torch.argmax(y, dim=1)\n",
    "        accuracy = torch.sum(torch.eq(v1, v2)) / len(y)\n",
    "        self.log(\"accuracy\", accuracy) # Accuracy for Accuracy vs. Parameter Experiment\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2034b-39fd-4e6a-8a75-7c611e697cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | net  | Sequential | 232 K  | train\n",
      "--------------------------------------------\n",
      "232 K     Trainable params\n",
      "0         Non-trainable params\n",
      "232 K     Total params\n",
      "0.929     Total estimated model params size (MB)\n",
      "157       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02817b9160b24cc6adb79259bb6ba988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train + Test + Results\n",
    "model = NetConvKAN()\n",
    "trained_model = L.Trainer(max_epochs=10, deterministic=True, logger=CSVLogger(save_dir=\"Experiments/logs\", name=\"CIFAR10ConvKANAcc\", version=\"fin\"), callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)])\n",
    "trained_model.fit(model, train_loader, val_loader)\n",
    "trained_model.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361431d-239c-4469-aed7-fd331b073238",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdata = pd.read_csv(\"Experiments/logs/CIFAR10ConvKANAcc/fin/metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915455b-7459-44bc-8641-acda4c0fd835",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindeflog = logdata.loc[logdata['train_loss'].notna(), ['step', 'train_loss']]\n",
    "valdeflog = logdata.loc[logdata['val_loss'].notna(), ['step', 'val_loss']]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(traindeflog['step'], traindeflog['train_loss'], label=\"train loss\")\n",
    "ax.plot(valdeflog['step'], valdeflog['val_loss'], label=\"validation loss\")\n",
    "ax.set(xlabel=\"step\", ylabel=\"loss\", title=\"Loss vs. Step\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa1a89-35c5-460f-b5a1-d94202ea2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R: True Value, C: Predicted Value\n",
    "def make_predict_matrix(model, dataloader):\n",
    "    res = np.zeros(shape=(10, 10), dtype=int)\n",
    "    model = model.to(device)\n",
    "    for it in iter(dataloader):\n",
    "        x, y = it\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x_arg = torch.argmax(model.forward(x), dim=1)\n",
    "        y_arg = torch.argmax(y, dim=1)\n",
    "        for i in range(len(x_arg)):\n",
    "            res[y_arg[i], x_arg[i]] += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580942b-37cd-445c-b276-3a7c856b8633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_predict_matrix(model, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
