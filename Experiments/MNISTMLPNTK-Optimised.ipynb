{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479bcedb-b14c-41f7-baca-bc5e77d9d2a9",
   "metadata": {},
   "source": [
    "# MLP + MNIST + NTK\n",
    "Purpose: Fit a FFNN to the MNIST dataset, for benchmarking the KAN performance.\n",
    "\n",
    "Furthermore, the PyTorch Lightning library is used for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5906942-d959-4742-a7f5-3f0d9d1eb9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 998244353\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import sys\n",
    "sys.path.append('../convkans/kan_convolutional')\n",
    "from KANLinear import *\n",
    "\n",
    "# Setup Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Setup Randomness -- https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "L.seed_everything(998244353, workers=True)\n",
    "\n",
    "# CUDA Efficiency\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298f7983-dee7-49b7-a4b8-87218d313bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Setup -- Inspired by Hugo's Dataset Reformatting\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = MNIST(\"./temp/\", train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(\"./temp/\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Reformatted, due to odd issues when using NTK on it\n",
    "class LCDataset(Dataset): # Lightning Compatible Dataset\n",
    "    def __init__(self, dataset, num_classes, limit=-1):\n",
    "        self.limit = limit\n",
    "        self.num_classes = num_classes\n",
    "        if self.limit != -1:\n",
    "            sub = list(np.random.permutation(np.arange(len(train_dataset)))[0:self.limit]) # Take a random sample of the first some elements.\n",
    "            self.dataset = Subset(dataset, sub)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        y_one_hot = torch.zeros(self.num_classes)\n",
    "        y_one_hot[y] = 1\n",
    "        return x, y_one_hot\n",
    "\n",
    "batch_size = 64\n",
    "ntk_loader = DataLoader(LCDataset(train_dataset, num_classes=10, limit=500), batch_size=batch_size, num_workers=10)\n",
    "train_loader = DataLoader(LCDataset(train_dataset, num_classes=10), batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "test_loader = DataLoader(LCDataset(test_dataset, num_classes=10), batch_size=batch_size, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf44a29-2a95-4e65-9372-1550ca2c8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Declaration\n",
    "class ClassicKAN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(14*14, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y) # MSE Loss works better for NTK\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y) # MSE Loss works better for NTK\n",
    "        v1 = torch.argmax(y_pred, dim=1)\n",
    "        v2 = torch.argmax(y, dim=1)\n",
    "        accuracy = torch.sum(torch.eq(v1, v2)) / len(y)\n",
    "        self.log(\"test loss (Cross Entropy Loss)\", loss)\n",
    "        self.log(\"accuracy\", accuracy)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4, weight_decay=2e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b2034b-39fd-4e6a-8a75-7c611e697cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | net  | Sequential | 13.3 K | train\n",
      "--------------------------------------------\n",
      "13.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 K    Total params\n",
      "0.053     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c438779c4a84b24be67b7b51025c86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1407777206d843ab9dfbb5a3798893b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">          Test metric           </span>┃<span style=\"font-weight: bold\">          DataLoader 0          </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            accuracy            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.9743000268936157       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test loss (Cross Entropy Loss) </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.0833774209022522       </span>│\n",
       "└────────────────────────────────┴────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         Test metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m         DataLoader 0         \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           accuracy           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9743000268936157      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest loss (Cross Entropy Loss)\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.0833774209022522      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────┴────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test loss (Cross Entropy Loss)': 0.0833774209022522,\n",
       "  'accuracy': 0.9743000268936157}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train + Test + Results\n",
    "model = ClassicKAN()\n",
    "trained_model = L.Trainer(max_epochs=80, deterministic=True, logger=CSVLogger(\"logs\", name=\"MNISTMLPNTK\"))\n",
    "trained_model.fit(model, train_loader)\n",
    "trained_model.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46fc063-69f9-4b6c-b828-0532713513f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NTK\n",
    "%run -i './introduction_code_modified.py'\n",
    "\n",
    "def cross_entropy_loss_batch(y_hat, y):\n",
    "    return F.cross_entropy(y_hat, y, reduction='none')\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "ntk_model = GaussianFit(model=model, device=device, noise_var=0.0)\n",
    "ntk_model.fit(ntk_loader, optimizer, MSELoss_batch) # MSELoss seems to work better for NTK Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d581c53c-624a-4cce-ac29-9802c4b720b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ntk_acc(model, dataloader):\n",
    "    res = 0.0\n",
    "    sumlength = 0\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for it in iter(dataloader):\n",
    "        x, y = it\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        sumlength += len(x)\n",
    "        res += (torch.argmax(model.forward(x), dim=1) == torch.argmax(y, dim=1)).sum()\n",
    "    model.train()\n",
    "    return res / sumlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48403686-91b7-4404-9e9d-ee7befcc3d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTK Accuracy: 0.6288999915122986\n"
     ]
    }
   ],
   "source": [
    "print(f'NTK Accuracy: {check_ntk_acc(ntk_model, test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfa1a89-35c5-460f-b5a1-d94202ea2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R: True Value, C: Predicted Value\n",
    "def make_predict_matrix(model, dataloader):\n",
    "    res = np.zeros(shape=(10, 10), dtype=int)\n",
    "    for it in iter(dataloader):\n",
    "        x, y = it\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x_arg = torch.argmax(model.forward(x), dim=1)\n",
    "        y_arg = torch.argmax(y, dim=1)\n",
    "        for i in range(len(x_arg)):\n",
    "            res[y_arg[i], x_arg[i]] += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ed94fc-995a-4354-8f6b-258a46283921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[694  59  17  45  45  26  13  10  35  36]\n",
      " [ 32 945  10   4   1  41  25  15  13  49]\n",
      " [ 39  45 580  52  51  99  26  41  49  50]\n",
      " [ 47  64  15 485  55  80 110  44  61  49]\n",
      " [ 37  53  20  35 633  37  40  56  36  35]\n",
      " [ 42  30  25  37  43 545  36  59  29  46]\n",
      " [ 46  54  22  66  34  30 512  65  36  93]\n",
      " [ 64  41  27  39  61  59 101 551  39  46]\n",
      " [ 29  41  25  41  45  58  34  32 618  51]\n",
      " [ 41  85  32  53  35  27  62  42  43 589]]\n"
     ]
    }
   ],
   "source": [
    "print(make_predict_matrix(ntk_model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b580942b-37cd-445c-b276-3a7c856b8633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 972    0    1    0    1    0    2    1    2    1]\n",
      " [   1 1125    4    0    0    0    3    0    2    0]\n",
      " [   7    2 1006    3    3    0    3    4    4    0]\n",
      " [   1    0    7  985    0    6    0    3    5    3]\n",
      " [   1    1    2    0  953    0    7    4    0   14]\n",
      " [   4    0    1   10    0  862    7    0    6    2]\n",
      " [   9    2    1    1    1    3  936    0    5    0]\n",
      " [   0    6   13    2    1    0    0  996    2    8]\n",
      " [   4    3    4   10    4    3    1    3  941    1]\n",
      " [   1    7    0   11    9    3    1    4    4  969]]\n"
     ]
    }
   ],
   "source": [
    "print(make_predict_matrix(model, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
