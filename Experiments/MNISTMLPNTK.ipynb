{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479bcedb-b14c-41f7-baca-bc5e77d9d2a9",
   "metadata": {},
   "source": [
    "# MLP + MNIST + NTK\n",
    "Purpose: Fit a FFNN to the MNIST dataset, for benchmarking the KAN performance.\n",
    "\n",
    "Furthermore, the PyTorch Lightning library is used for convenience.\n",
    "\n",
    "I've copied some parts from the KAN experimentation, due to there being some degree of overlap between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5906942-d959-4742-a7f5-3f0d9d1eb9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# Setup Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Setup Randomness -- https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "L.seed_everything(42, workers=True)\n",
    "\n",
    "# CUDA Efficiency\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298f7983-dee7-49b7-a4b8-87218d313bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Setup\n",
    "train_dataset = MNIST(\"./temp/\", train=True, download=True)\n",
    "test_dataset = MNIST(\"./temp/\", train=False, download=True)\n",
    "\n",
    "class LCDataset(Dataset): # Lightning Compatible Dataset\n",
    "    def __init__(self, dataset, limit=-1):\n",
    "        self.limit = limit\n",
    "        if self.limit != -1:\n",
    "            self.sub = list(np.random.permutation(np.arange(len(train_dataset)))[0:self.limit]) # Take a random sample of the first some elements.\n",
    "            self.data = dataset.data[self.sub, :, :].view(-1, 28*28).type(torch.float32)\n",
    "            self.target = torch.tensor((pd.get_dummies(pd.Series(dataset.targets[self.sub].numpy())).map(lambda x: 1 if x == True else 0)).values).type(torch.float32)\n",
    "        else:\n",
    "            self.data = dataset.data.view(-1, 28*28).type(torch.float32)\n",
    "            self.target = torch.tensor((pd.get_dummies(pd.Series(dataset.targets.numpy())).map(lambda x: 1 if x == True else 0)).values).type(torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "train_loader = DataLoader(LCDataset(train_dataset, limit=2750), batch_size=64, shuffle=True, num_workers=10)\n",
    "test_loader = DataLoader(LCDataset(test_dataset), batch_size=64, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf44a29-2a95-4e65-9372-1550ca2c8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Declaration\n",
    "class FFNNMLP(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28, 240),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(240, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        v1 = torch.argmax(y_pred, dim=1)\n",
    "        v2 = torch.argmax(y, dim=1)\n",
    "        accuracy = torch.sum(torch.eq(v1, v2)) / len(y)\n",
    "        self.log(\"test loss (cross entropy)\", loss)\n",
    "        self.log(\"accuracy\", accuracy)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b2034b-39fd-4e6a-8a75-7c611e697cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | net  | Sequential | 203 K  | train\n",
      "--------------------------------------------\n",
      "203 K     Trainable params\n",
      "0         Non-trainable params\n",
      "203 K     Total params\n",
      "0.814     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a9c9a58eb74f54b91581ff2e337843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fb14596cd64c909e1a7a669e9388bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9089999794960022     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test loss (cross entropy) </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48374447226524353    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9089999794960022    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest loss (cross entropy)\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48374447226524353   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test loss (cross entropy)': 0.48374447226524353,\n",
       "  'accuracy': 0.9089999794960022}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train + Test + Results\n",
    "model = FFNNMLP()\n",
    "trained_model = L.Trainer(max_epochs=100, deterministic=True, logger=CSVLogger(\"logs\", name=\"MNISTMLPNTK\"), log_every_n_steps=25)\n",
    "trained_model.fit(model, train_loader)\n",
    "trained_model.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46fc063-69f9-4b6c-b828-0532713513f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NTK\n",
    "%run -i 'misc/introduction_code_modded_KAN_NTK.py'\n",
    "\n",
    "def cross_entropy_loss_batch(y_hat, y):\n",
    "    return F.cross_entropy(y_hat, y, reduction='none')\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "ntk_model = GaussianFit(model=model, device=device, noise_var=0.0)\n",
    "ntk_model.fit(train_loader, optimizer, cross_entropy_loss_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45a18ac-b07e-49d1-ade8-eaa90e0d451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ntk_acc(model, dataloader):\n",
    "    res = 0.0\n",
    "    sumlength = 0\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for it in iter(dataloader):\n",
    "        x, y = it\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        sumlength += len(x)\n",
    "        res += (torch.argmax(model.forward(x), dim=1) == torch.argmax(y, dim=1)).sum()\n",
    "    model.train()\n",
    "    return res / sumlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf4526c-a5c0-461d-8d2e-fdcf3c8cd68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTK Accuracy: 0.18639999628067017\n"
     ]
    }
   ],
   "source": [
    "print(f'NTK Accuracy: {check_ntk_acc(ntk_model, test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aaabfbc-cbdc-41cf-b3c0-e1b3bc126074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R: True Value, C: Predicted Value\n",
    "def make_predict_matrix(model, dataloader):\n",
    "    res = np.zeros(shape=(10, 10), dtype=int)\n",
    "    for it in iter(dataloader):\n",
    "        x, y = it\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x_arg = torch.argmax(model.forward(x), dim=1)\n",
    "        y_arg = torch.argmax(y, dim=1)\n",
    "        for i in range(len(x_arg)):\n",
    "            res[y_arg[i], x_arg[i]] += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062d83ec-dedc-41f2-83f2-246997524456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  65  91 123  85 133  81  98  54  75]\n",
      " [ 36 351 107  97 100 102  76 118  74  74]\n",
      " [ 62 102 203 109 103 101  91 114  92  55]\n",
      " [ 41 120 139 173 119 125  57  80  90  66]\n",
      " [ 51  69  88 119 178 120  96 102  72  87]\n",
      " [ 35  93  80 123 109 161  66  73  85  67]\n",
      " [ 59  56 132 114 142 125 121  71  72  66]\n",
      " [ 56  74 114 139 138  77  61 199  69 101]\n",
      " [ 58  81  98  96 152 101  69  97 137  85]\n",
      " [ 56  73 102  96 138  85  89 122  82 166]]\n"
     ]
    }
   ],
   "source": [
    "print(make_predict_matrix(ntk_model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8887ff19-e1ff-4a48-9e3a-3e8ad2fa5c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 938    0    2    1    3   10    7    2   13    4]\n",
      " [   0 1113    5    3    1    1    4    1    7    0]\n",
      " [  15    3  908   16   11    7   14   27   26    5]\n",
      " [   8    2   24  870    0   34    8   19   36    9]\n",
      " [   5    3    4    0  880    0   11    2    4   73]\n",
      " [   5    4    7   25    7  779   28    5   26    6]\n",
      " [  15    3    9    0    8    7  914    0    2    0]\n",
      " [   2   12   14    6   12    4    4  950    1   23]\n",
      " [  15    6   15   17   11   14   14   25  833   24]\n",
      " [   5    6    3    9   30    9    2   32    8  905]]\n"
     ]
    }
   ],
   "source": [
    "print(make_predict_matrix(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0943b87-91e5-478a-a184-a54417dcefd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
