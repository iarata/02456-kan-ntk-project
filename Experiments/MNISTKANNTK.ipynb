{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479bcedb-b14c-41f7-baca-bc5e77d9d2a9",
   "metadata": {},
   "source": [
    "# KAN + MNIST + NTK\n",
    "Purpose: Fit a KAN to the MNIST dataset, for benchmarking the KAN performance.\n",
    "\n",
    "Furthermore, the PyTorch Lightning library is used for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5906942-d959-4742-a7f5-3f0d9d1eb9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import sys\n",
    "sys.path.append('../convkans/kan_convolutional')\n",
    "from KANLinear import *\n",
    "\n",
    "# Setup Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Setup Randomness -- https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "L.seed_everything(42, workers=True)\n",
    "\n",
    "# CUDA Efficiency\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298f7983-dee7-49b7-a4b8-87218d313bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Setup\n",
    "train_dataset = MNIST(\"./temp/\", train=True, download=True)\n",
    "test_dataset = MNIST(\"./temp/\", train=False, download=True)\n",
    "\n",
    "class LCDataset(Dataset): # Lightning Compatible Dataset\n",
    "    def __init__(self, dataset, limit=-1):\n",
    "        self.limit = limit\n",
    "        if self.limit != -1:\n",
    "            self.sub = list(np.random.permutation(np.arange(len(train_dataset)))[0:self.limit]) # Take a random sample of the first some elements.\n",
    "            self.data = dataset.data[self.sub, :, :].view(-1, 28*28).type(torch.float32)\n",
    "            self.target = torch.tensor((pd.get_dummies(pd.Series(dataset.targets[self.sub].numpy())).map(lambda x: 1 if x == True else 0)).values).type(torch.float32)\n",
    "        else:\n",
    "            self.data = dataset.data.view(-1, 28*28).type(torch.float32)\n",
    "            self.target = torch.tensor((pd.get_dummies(pd.Series(dataset.targets.numpy())).map(lambda x: 1 if x == True else 0)).values).type(torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "train_loader = DataLoader(LCDataset(train_dataset, limit=500), batch_size=8, shuffle=True, num_workers=10)\n",
    "test_loader = DataLoader(LCDataset(test_dataset), batch_size=8, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf44a29-2a95-4e65-9372-1550ca2c8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Declaration\n",
    "class ClassicKAN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            KAN(layers_hidden=[28*28, 240, 60, 10], grid_size=2, spline_order=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        v1 = torch.argmax(y_pred, dim=1)\n",
    "        v2 = torch.argmax(y, dim=1)\n",
    "        accuracy = torch.sum(torch.eq(v1, v2)) / len(y)\n",
    "        self.log(\"test loss (cross entropy)\", loss)\n",
    "        self.log(\"accuracy\", accuracy)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b2034b-39fd-4e6a-8a75-7c611e697cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | net  | Sequential | 1.2 M  | train\n",
      "--------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.876     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ddedf8aa6f4d49b0461b9df175408c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc7e3d9d3ad415cbc9aa6a8f66ba003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.829800009727478     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test loss (cross entropy) </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8854795098304749     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.829800009727478    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest loss (cross entropy)\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8854795098304749    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test loss (cross entropy)': 0.8854795098304749,\n",
       "  'accuracy': 0.829800009727478}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train + Test + Results\n",
    "model = ClassicKAN()\n",
    "trained_model = L.Trainer(max_epochs=100, deterministic=True, logger=CSVLogger(\"logs\", name=\"MNISTKAN\"))\n",
    "trained_model.fit(model, train_loader)\n",
    "trained_model.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46fc063-69f9-4b6c-b828-0532713513f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NTK\n",
    "%run -i 'misc/introduction_code_modded_KAN_NTK.py'\n",
    "\n",
    "def cross_entropy_loss_batch(y_hat, y):\n",
    "    return F.cross_entropy(y_hat, y, reduction='none')\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "ntk_model = GaussianFit(model=model, device=device, noise_var=0.0)\n",
    "ntk_model.fit(train_loader, optimizer, MSELoss_batch) # MSELoss seems to work better for NTK Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d581c53c-624a-4cce-ac29-9802c4b720b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ntk_acc(model, dataloader):\n",
    "    res = 0.0\n",
    "    sumlength = 0\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for it in iter(dataloader):\n",
    "        x, y = it\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        sumlength += len(x)\n",
    "        res += (torch.argmax(model.forward(x), dim=1) == torch.argmax(y, dim=1)).sum()\n",
    "    model.train()\n",
    "    return res / sumlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48403686-91b7-4404-9e9d-ee7befcc3d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTK Accuracy: 0.28999999165534973\n"
     ]
    }
   ],
   "source": [
    "print(f'NTK Accuracy: {check_ntk_acc(ntk_model, test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfa1a89-35c5-460f-b5a1-d94202ea2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R: True Value, C: Predicted Value\n",
    "def make_predict_matrix(model, dataloader):\n",
    "    res = np.zeros(shape=(10, 10), dtype=int)\n",
    "    for it in iter(dataloader):\n",
    "        x, y = it\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x_arg = torch.argmax(model.forward(x), dim=1)\n",
    "        y_arg = torch.argmax(y, dim=1)\n",
    "        for i in range(len(x_arg)):\n",
    "            res[y_arg[i], x_arg[i]] += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ed94fc-995a-4354-8f6b-258a46283921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[314 101  55  58  51  89  79  96  96  41]\n",
      " [ 39 428  49 104 170  15 133  68  66  63]\n",
      " [ 48  81 326  91 104  56  98 104  72  52]\n",
      " [ 67  68 114 344  62  44  79 100  63  69]\n",
      " [ 74  79  79  74 268  61  87  82  63 115]\n",
      " [ 73  62  50  89  49 215  77  69 116  92]\n",
      " [ 76 114  73  41  94  46 268  35  77 134]\n",
      " [127  62  47 136  63  37  95 308  63  90]\n",
      " [ 90  72  64  85  59  73  79  75 259 118]\n",
      " [ 49  64  95 130 161  71 124  90  55 170]]\n"
     ]
    }
   ],
   "source": [
    "print(make_predict_matrix(ntk_model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b580942b-37cd-445c-b276-3a7c856b8633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 874    1   24    3    2   40   29    0    5    2]\n",
      " [   2 1109    4    1    0    3    3    3   10    0]\n",
      " [  29   12  822   34   31   10   26   18   47    3]\n",
      " [  17    7   29  804   11   49   15   21   40   17]\n",
      " [   1    0    6    2  839    0   17    4   20   93]\n",
      " [  23   11   17   71   15  636   33   12   63   11]\n",
      " [  59    2   24    2   24   27  816    0    4    0]\n",
      " [   2   15   12   12   24    8    3  882   18   52]\n",
      " [  48   22    6   32   15   47   23   29  720   32]\n",
      " [  25    6    4    5   88    3    2   70   10  796]]\n"
     ]
    }
   ],
   "source": [
    "print(make_predict_matrix(model, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
